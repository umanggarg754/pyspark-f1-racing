{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96fd5287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.4.3.tar.gz (311.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:10\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.7 (from pyspark)\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.4.3-py2.py3-none-any.whl size=311885494 sha256=df8ccdec85a9356c2f1680400b89f118b1cc41d0de37ac6c2acd5a8a1b3a2ee0\n",
      "  Stored in directory: /Users/umang/Library/Caches/pip/wheels/37/bc/bb/77785f6fcd2c83e663647f73225b76f3a3d5fd00762d7daf6f\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.4.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T13:57:44.839288Z",
     "start_time": "2024-09-25T13:57:44.834767Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType, BooleanType, DateType, DecimalType, DoubleType\n",
    "from pyspark.sql.functions import col, when, sum, avg, row_number\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad9d3d3e9a84965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:00:19.993394Z",
     "start_time": "2024-09-25T14:00:19.919422Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/05 20:12:21 WARN Utils: Your hostname, Admins-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.10.104 instead (on interface en0)\n",
      "24/10/05 20:12:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/05 20:12:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"F1 Data Analysis\").config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .getOrCreate()\n",
    " # .config(\"spark.hadoop.fs.s3a.access.key\", \"AKIA6FXCAGDVQXS4E6WW\") \\\n",
    "    # .config(\"spark.hadoop.fs.s3a.secret.key\", \"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\") \\\n",
    "    # .config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad087aeca91ff54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T11:44:43.419737Z",
     "start_time": "2024-09-25T11:44:43.414151Z"
    }
   },
   "outputs": [],
   "source": [
    "circuit_schema = StructType([\n",
    "    StructField(\"circuitId\", IntegerType(), False),\n",
    "    StructField(\"circuitRef\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"lat\", DoubleType(), True),\n",
    "    StructField(\"lng\", DoubleType(), True),\n",
    "    StructField(\"alt\", IntegerType(), True),\n",
    "    StructField(\"url\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e984f8125653911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T11:45:23.335094Z",
     "start_time": "2024-09-25T11:45:21.865610Z"
    }
   },
   "outputs": [],
   "source": [
    "circuits = spark.read.schema(circuit_schema).format(\"csv\").option(\"header\",\"true\").load(\"data/circuits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc1c35e743671fbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T11:45:39.152050Z",
     "start_time": "2024-09-25T11:45:34.945074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+--------------------+------------+---------+--------+-------+---+--------------------+\n",
      "|circuitId| circuitRef|                name|    location|  country|     lat|    lng|alt|                 url|\n",
      "+---------+-----------+--------------------+------------+---------+--------+-------+---+--------------------+\n",
      "|        1|albert_park|Albert Park Grand...|   Melbourne|Australia|-37.8497|144.968| 10|http://en.wikiped...|\n",
      "|        2|     sepang|Sepang Internatio...|Kuala Lumpur| Malaysia| 2.76083|101.738| 18|http://en.wikiped...|\n",
      "|        3|    bahrain|Bahrain Internati...|      Sakhir|  Bahrain| 26.0325|50.5106|  7|http://en.wikiped...|\n",
      "|        4|  catalunya|Circuit de Barcel...|    Montmeló|    Spain|   41.57|2.26111|109|http://en.wikiped...|\n",
      "|        5|   istanbul|       Istanbul Park|    Istanbul|   Turkey| 40.9517| 29.405|130|http://en.wikiped...|\n",
      "|        6|     monaco|   Circuit de Monaco| Monte-Carlo|   Monaco| 43.7347|7.42056|  7|http://en.wikiped...|\n",
      "+---------+-----------+--------------------+------------+---------+--------+-------+---+--------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "circuits.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee400fe65704391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T11:47:58.259237Z",
     "start_time": "2024-09-25T11:47:57.337513Z"
    }
   },
   "outputs": [],
   "source": [
    "races = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"True\").load(\"data/races.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a06f0dd321ccaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T11:50:14.252059Z",
     "start_time": "2024-09-25T11:50:14.245962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raceId',\n",
       " 'year',\n",
       " 'round',\n",
       " 'circuitId',\n",
       " 'name',\n",
       " 'date',\n",
       " 'time',\n",
       " 'url',\n",
       " 'fp1_date',\n",
       " 'fp1_time',\n",
       " 'fp2_date',\n",
       " 'fp2_time',\n",
       " 'fp3_date',\n",
       " 'fp3_time',\n",
       " 'quali_date',\n",
       " 'quali_time',\n",
       " 'sprint_date',\n",
       " 'sprint_time']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races.columns\n",
    "#races.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7c8a17eb976e7be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T11:49:19.425961Z",
     "start_time": "2024-09-25T11:49:19.363883Z"
    }
   },
   "outputs": [],
   "source": [
    "circuits.createOrReplaceTempView(\"circuits\")\n",
    "races.createOrReplaceTempView(\"races\")\n",
    "# not required in pyspark now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c6f62d9054c1392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T11:51:54.971652Z",
     "start_time": "2024-09-25T11:51:54.938274Z"
    }
   },
   "outputs": [],
   "source": [
    "races_in__each_circuits = spark.sql(\"select count(*),c.name from races r join circuits c on c.circuitId=r.circuitId group by c.name order by count(*) desc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9bf6bcd69f67c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T12:15:01.047928Z",
     "start_time": "2024-09-25T12:15:00.336306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|count(1)|                name|\n",
      "+--------+--------------------+\n",
      "|      74|Autodromo Naziona...|\n",
      "|      70|   Circuit de Monaco|\n",
      "|      59| Silverstone Circuit|\n",
      "|      57|Circuit de Spa-Fr...|\n",
      "|      43|Circuit Gilles Vi...|\n",
      "|      41|Autódromo José Ca...|\n",
      "|      41|         Nürburgring|\n",
      "|      39|         Hungaroring|\n",
      "|      38|       Red Bull Ring|\n",
      "|      37|      Hockenheimring|\n",
      "+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most popular circuits\n",
    "races_in__each_circuits.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42adfe7131fef725",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T12:18:31.199424Z",
     "start_time": "2024-09-25T12:18:30.984071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2024|   24|\n",
      "|2023|   22|\n",
      "|2022|   22|\n",
      "|2021|   22|\n",
      "|2020|   17|\n",
      "|2019|   21|\n",
      "|2018|   21|\n",
      "|2017|   20|\n",
      "|2016|   21|\n",
      "|2015|   19|\n",
      "+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# races per year \n",
    "races.groupBy('year').count().sort(col(\"year\").desc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25f8f0ad0f7cb901",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T13:57:26.595246Z",
     "start_time": "2024-09-25T13:57:25.676171Z"
    }
   },
   "outputs": [],
   "source": [
    "# average races per decade \n",
    "races_in__each_decade = spark.sql(\"select count(*),(int(year/10))*10 from races r join circuits c on c.circuitId=r.circuitId group by (int(year/10))*10 order by (int(year/10))*10 desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfcb975a364b0c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|count(1)|((year / 10) * 10)|\n",
      "+--------+------------------+\n",
      "|     107|              2020|\n",
      "|     198|              2010|\n",
      "|     174|              2000|\n",
      "|     162|              1990|\n",
      "|     156|              1980|\n",
      "|     144|              1970|\n",
      "|     100|              1960|\n",
      "|      84|              1950|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "races_in__each_decade.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8e59679",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"True\").load(\"data/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ee77785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+-------------+------+----+--------+------------+-------------+------+----+-----------+------------+----------+----+--------------+---------------+--------+\n",
      "|resultId|raceId|driverId|constructorId|number|grid|position|positionText|positionOrder|points|laps|       time|milliseconds|fastestLap|rank|fastestLapTime|fastestLapSpeed|statusId|\n",
      "+--------+------+--------+-------------+------+----+--------+------------+-------------+------+----+-----------+------------+----------+----+--------------+---------------+--------+\n",
      "|       1|    18|       1|            1|    22|   1|       1|           1|            1|  10.0|  58|1:34:50.616|     5690616|        39|   2|      1:27.452|        218.300|       1|\n",
      "|       2|    18|       2|            2|     3|   5|       2|           2|            2|   8.0|  58|     +5.478|     5696094|        41|   3|      1:27.739|        217.586|       1|\n",
      "|       3|    18|       3|            3|     7|   7|       3|           3|            3|   6.0|  58|     +8.163|     5698779|        41|   5|      1:28.090|        216.719|       1|\n",
      "|       4|    18|       4|            4|     5|  11|       4|           4|            4|   5.0|  58|    +17.181|     5707797|        58|   7|      1:28.603|        215.464|       1|\n",
      "|       5|    18|       5|            1|    23|   3|       5|           5|            5|   4.0|  58|    +18.014|     5708630|        43|   1|      1:27.418|        218.385|       1|\n",
      "|       6|    18|       6|            3|     8|  13|       6|           6|            6|   3.0|  57|         \\N|          \\N|        50|  14|      1:29.639|        212.974|      11|\n",
      "|       7|    18|       7|            5|    14|  17|       7|           7|            7|   2.0|  55|         \\N|          \\N|        54|   8|      1:29.534|        213.224|       5|\n",
      "|       8|    18|       8|            6|     1|  15|       8|           8|            8|   1.0|  53|         \\N|          \\N|        20|   4|      1:27.903|        217.180|       5|\n",
      "|       9|    18|       9|            2|     4|   2|      \\N|           R|            9|   0.0|  47|         \\N|          \\N|        15|   9|      1:28.753|        215.100|       4|\n",
      "|      10|    18|      10|            7|    12|  18|      \\N|           R|           10|   0.0|  43|         \\N|          \\N|        23|  13|      1:29.558|        213.166|       3|\n",
      "|      11|    18|      11|            8|    18|  19|      \\N|           R|           11|   0.0|  32|         \\N|          \\N|        24|  15|      1:30.892|        210.038|       7|\n",
      "|      12|    18|      12|            4|     6|  20|      \\N|           R|           12|   0.0|  30|         \\N|          \\N|        20|  16|      1:31.384|        208.907|       8|\n",
      "|      13|    18|      13|            6|     2|   4|      \\N|           R|           13|   0.0|  29|         \\N|          \\N|        23|   6|      1:28.175|        216.510|       5|\n",
      "|      14|    18|      14|            9|     9|   8|      \\N|           R|           14|   0.0|  25|         \\N|          \\N|        21|  11|      1:29.502|        213.300|       4|\n",
      "|      15|    18|      15|            7|    11|   6|      \\N|           R|           15|   0.0|  19|         \\N|          \\N|        18|  10|      1:29.310|        213.758|      10|\n",
      "|      16|    18|      16|           10|    20|  22|      \\N|           R|           16|   0.0|   8|         \\N|          \\N|         8|  17|      1:32.021|        207.461|       9|\n",
      "|      17|    18|      17|            9|    10|  14|      \\N|           R|           17|   0.0|   0|         \\N|          \\N|        \\N|  \\N|            \\N|             \\N|       4|\n",
      "|      18|    18|      18|           11|    16|  12|      \\N|           R|           18|   0.0|   0|         \\N|          \\N|        \\N|  \\N|            \\N|             \\N|       4|\n",
      "|      19|    18|      19|            8|    19|  21|      \\N|           R|           19|   0.0|   0|         \\N|          \\N|        \\N|  \\N|            \\N|             \\N|       4|\n",
      "|      20|    18|      20|            5|    15|   9|      \\N|           R|           20|   0.0|   0|         \\N|          \\N|        \\N|  \\N|            \\N|             \\N|       4|\n",
      "+--------+------+--------+-------------+------+----+--------+------------+-------------+------+----+-----------+------------+----------+----+--------------+---------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956735e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
